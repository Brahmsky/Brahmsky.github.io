---
layout: post
title: "正则化"
author: "Brahmsky"
date: 2025-07-29 18:00:00 +0800  # 文章发布日期和时间（可选，但推荐）
categories: [深度学习, PyTorch]      # 文章分类（可以是多个）
tags: [Transformer, 注意力机制, NLP] # 文章标签（可以是多个）
catalog: true                       # 是否显示目录 (根据你的主题)
header-style: text                  # 头部样式 (根据你的主题)
---
应该采用验证集上的代价函数变大还是准确率下降的时间点来判断过拟合？这两种方法并不矛盾：如果想**尽早发现过拟合并优化模型泛化能力**，关注**验证集损失**；如果想知道过拟合**何时开始影响你的最终分类准确率目标**，那么关注**验证集准确率**的下降点也是合理的

在大多数深度学习实践中，为了获得最佳的泛化模型，通常会监控验证集损失（而不是验证集准确率），并在其开始上升时停止训练。（和这本深度学习书中介绍的相反）

提前停止：神经元饱和就停止训练。但是不知道什么时候饱和，所以是一个可能激进也可能温和的策略
L2正则化/权重衰减：$$C = C_0 + \frac{\lambda}{2n} \sum_{j} w_j^2$$
四个基本方程来镇场：
![[Pasted image 20250728184216.png]]我们可以发现，单个样本的BP1和BP2、BP3的形式都不会变，只有最后单个样本C对w的梯度会变成$$ \frac{\partial C}{\partial w} = \frac{\partial C_0}{\partial w} + \frac{\lambda}{n} w $$
于是，单个样本权重的学习规则变成了 $w \leftarrow w - \eta \left( \frac{\partial C_0}{\partial w} + \frac{\lambda}{n} w \right)$ ，即 $$w \leftarrow \left( 1 - \frac{\eta \lambda}{n} \right) w - \eta \frac{\partial C_0}{\partial w}$$
对于SGD来讲，形式就是$$ w \leftarrow \left( 1 - \frac{\eta \lambda}{n} \right) w - \frac{\eta}{m} \sum_{x} \frac{\partial C_0^{x}}{\partial w} $$
可以看到，w前面有一个衰减因子。那么，w难道不会一直衰减到0吗？
并不会。因为公式中存在两项，权重衰减项会将w推向0，而原始损失梯度项会将w推向最小化$C_0$的方向。如果 w 衰减到非常接近0，那么模型将变得非常简单，甚至无法捕捉数据中的任何模式，$C_0$​就会变得非常大，它的梯度 $∂C_0/∂w$也会变得非常大，并且指向能够减小$C_0$的方向，产生一个强大的“拉力”，将权重 w 从零的方向拉回来，使其能够更好地拟合数据。
最终，w 会在一个非零的值附近达到一个平衡点，**收缩**(shrink)到一个较小但非零的值，使得所有特征都对模型有所贡献，但它们的贡献被限制在一定范围内，提高了模型的泛化能力。在这个平衡点上，来自原始损失函数的“拉力”与来自正则化项的“推力”（衰减）相互抵消。

为什么非正则化的代价函数容易过拟合？
**寻找复杂解：** 如果没有权重惩罚项，为了完美拟合训练数据（包括其中的噪声），模型可能会倾向于学习非常大的权重，因为大的权重可以使得模型对输入的变化非常敏感，从而在训练数据上实现非常精确的拟合。
**多重最优解：** 对于某些损失函数和网络结构，可能存在多组权重都能达到相似的低训练误差。其中一些解可能包含非常大的权重。如果没有正则化，优化器可能会“漂移”到这些大权重的解空间。
最要紧的是，权重向量(L2范数)过长时，就可能导致激活函数饱和，梯度消失

类比对一个用低维多项式和高维多项式去拟合平面数据点的例子。次数高意味着对输入敏感，噪声敏感，大权重网络一些特定神经元的表现也会对输入敏感。正则化的神经网络有更小的权重，意味着神经网络的行为不会因为一个输入的改变而显著改变，不容易学习局部噪声的影响，倾向于学习训练数据中的常规模式，构造相对简单的模型，对整个训练集中经常出现的情况做出反应。

**大神经网络（特别是过参数化模型，即参数数量远超训练数据量的模型）似乎确实存在一种“自正则化”效应（Self-Regularization Effect）或“隐式正则化”（Implicit Regularization）。**

为什么不正则化偏置项？  
b 的作用是**调整激活函数的输入范围**，将激活函数的输出曲线进行平移，使其能够更好地适应数据的分布，不影响模型对输入特征的敏感度或特征之间的相对重要性，不直接控制模型的“复杂度”或“平滑度”。如果正则化偏置项，可能会**限制模型的表达能力**，导致欠拟合。大的偏置反而可能让网络更灵活，因为偏置项允许神经元在没有输入或输入很小的情况下也能产生非零激活，或者在输入很小的情况下就能达到较高的激活水平，增加了模型的“灵活性”。


其他正则化技术：
L1正则化Lasso (Least Absolute Shrinkage and Selection Operator)：$$C = C_0 + \frac{\lambda}{n} \sum_{j} |w_j|$$
L1正则化之下的BP4： $$\frac{\partial C}{\partial w} = \frac{\partial C_0}{\partial w} + \frac{\lambda}{n} sgn(w)，for \ w_j \ ≠ 0 $$
此时权重更新规则变成了$w \leftarrow w - \eta \left( \frac{\partial C_0}{\partial w} + \frac{\lambda}{n} sgn(w) \right)，for \ w_j \ ≠ 0$。SGD形式：$$ w \leftarrow \ w - \frac{\eta \lambda}{n} sgn( w) - \frac{\eta}{m} \sum_{x} \frac{\partial C_0^{x}}{\partial w} $$
其正则化部分$- \frac{\eta \lambda}{n} sgn( w)$的作用都是：只看w正负，不管w多大，把w以一个固定拉力平等地往0方向上拉。相比于L2正则化(惩罚项梯度$\frac{\lambda}{n} w$，拉力大小与权重 w 成正比)，当权重接近零时，L2的拉力也随之减弱，因此它只能将权重**收缩到接近零，但很难精确为零**，而L1拉力固定，是其能够实现**稀疏性**的核心原因。（这里的稀疏性未必就真的代表大部分w都是0，可以只是一部分）
但是L1中$|w_j|$在$w_j = 0$处不可导，强行应用会导致权重不断地在零点附近**来回跳跃，改变符号**，无法精确停留到0，实现其“将权重精确地置为零，从而实现特征选择”的核心优势。
于是引入**次梯度 (subgradient)** 的概念：$$ \partial C = \frac{\partial C_0}{\partial w} + \frac{\lambda}{n} \cdot \text{subgradient}(|w|) $$
$|w|$在 $w_j​=0$ 处的次梯度，即那个未定义的$sgn(0)$项，是 [−1,1] 范围内的任何值。于是，就产生了一个**总损失函数 C 关于 w 的次梯度集合**。如果这个集合里包含零值，就可以直接将此时的 w 作为最优解。具体来说，**如果原始损失函数的梯度 $\left| \frac{\partial C_0}{\partial w} \right|$ ≤ $\frac{\lambda}{n}$，那么我们可以在次梯度集合 $[-1, 1]$ 中找到$sgn(w)$的一个值 $g$ （具体为 $g = -\frac{n}{\lambda} \frac{\partial C_0}{\partial w}$），把总梯度 $\frac{\partial C_0}{\partial w} + \frac{\lambda}{n} g$ 设置为零。**

以次梯度为理论依据，产生更精确和常用的表达方式**近端梯度下降（Proximal Gradient Descent）**，其核心是**软阈值操作（Soft Thresholding Operator）**：通过一个明确的阈值判断，当权重在经过原始梯度更新后其绝对值足够小时，会**直接将其强制设置为零**。可以用下面的操作作为L1的实际应用方式：
	1.梯度步：$w' = w - \eta \frac{\partial C_0}{\partial w}$，这个就是不带正则项的梯度下降
	2.**近端步(软阈值化)**，对这个临时的w值应用一个SoftThrehold：$w_{\text{new}} = \text{SoftThreshold}(w', \theta) = \text{sgn}(w') \max(0, |w'| - \theta)，其中\theta = \eta \frac{\lambda}{n}$。看着这个表达式不知道在讲啥，其实 $\text{SoftThreshold}(x, T) = \begin{cases} x - T & \text{if } x > T \\ x + T & \text{if } x < -T \\ 0 & \text{if } |x| \le T \end{cases}$。

可以从次梯度推导出这个阈值：次梯度中C对w等于0时的的次梯度集合存在0值的条件是$\left| \frac{\partial C_0}{\partial w} \right| \le \frac{\lambda}{n}$，软阈值操作中w = 0的条件是$|w'| \le \theta$。考虑软阈值实现中，当网络中的某个w在本轮更新之前已经为0，梯度步中临时权重就是 $w' = 0 - \eta \frac{\partial C_0}{\partial w} = -\eta \frac{\partial C_0}{\partial w}$，将其设置为0的条件是$|w'| \le \theta \implies \left| -\eta \frac{\partial C_0}{\partial w} \right| \le \theta$，即 $\left| \frac{\partial C_0}{\partial w} \right| \le \frac{\theta}{\eta}$。为了让软阈值操作在实践中能够**精确地表示**次梯度理论所定义的 w = 0 为最优解的条件，这两个条件必须是等价的，即$\frac{\theta}{\eta} = \frac{\lambda}{n}$。这就得到了软阈值化中的阈值$\theta = \eta \frac{\lambda}{n}$。
只有当一个特征的“重要性”（对原始损失的梯度大小）不足以抵消L1正则化的惩罚时，它的权重才会被压缩并保持在零，对于$∂w_j/​∂C_0$​​ 较大的特征，即使L1正则化试图将其推向零，原始损失函数的大梯度也会将其拉离零点。这就实现了一个**特征选择**的特性，能**自动识别并剔除不重要的特征**，产生更稀疏、更简单的模型，可解释性更强。

有没有把L1和L2结合起来的做法？有的兄弟有的。
**弹性网络 (Elastic Net)**，使用一个总的正则化强度 λ 和一个混合比 α，得到：$$ J_{regularized}(\mathbf{w}) = J_{original}(\mathbf{w}) + \lambda \left( (1-\alpha) \frac{1}{2} ||\mathbf{w}||_2^2 + \alpha ||\mathbf{w}||_1 \right) $$
这么搞可以结合L1特征选择和提取能力，同时提高**处理高度相关特征的稳定性 (L2的优点)：** 像L2一样，当存在高度相关的特征时，弹性网络会倾向于将这些相关特征的权重**一起收缩**，而不是随机选择一个。这意味着它会保留所有相关的特征，并给它们分配相似的（非零）权重，从而提高了模型的稳定性。其约束区域可以看成一个圆角菱形。

这个就涉及到L1和L2形式中的带约束最优化问题的几何解释了。”“啥叫“约束区域”？首先，需要明确最关键的优化目标：**在限制模型复杂度（通过限制权重大小）的前提下，尽可能地最小化原始损失函数**。从实际算法执行的角度来看，L1和L2这个”新的代价函数=原始代价函数+惩罚项“的优化方法，实际上是在最小化这个**新的代价函数**。但是这个在数学上，等价于**在一个特定约束区域内优化原始代价函数**：$\min_{\mathbf{w}} J_{original}(\mathbf{w}) \quad \text{subject to} \quad ||\mathbf{w}||_{\text{norm}} \le R$，这个约束区域就是$||\mathbf{w}||_{\text{norm}} \le R$定义的权重向量 w 必须落在的几何空间，或成为可行域。**在这个人为限制的空间里面，我们就认为这个模型具有很好的泛化能力**。
对于L1，这是一个超正八面体，对于L2，这是一个超球体，对于弹性网络，这是一个”超圆角菱形“。不论形状如何，向量范数的自由度n总是等于其维数，所以理解这个约束下取得最优条件的关键，在于想象一个n维几何体在一个”(θ，C)“的n+1维空间里面与原始损失函数相切。在几何上，找到的最优解 $\mathbf{w}^*_{reg}$ 是**原始损失函数 $J_{original}(\mathbf{w})$ 的等高线（或等值面）与正则化约束区域的边界（或表面）的第一个相切点。

至于多重共线性是指在回归模型中，**一个或多个自变量（特征）之间存在高度相关性**。简单来说，就是某些特征的信息是重复的，它们可以被其他特征线性表示。
**完美共线性：** 一个模型预测房价，其中一个特征是“房屋面积（平方米）”，另一个特征是“房屋面积（平方英尺）”。这两个特征是完全线性相关的（1平方米 = 10.764平方英尺）
**高度共线性：** 预测房价时，特征有“房屋卧室数量”和“房屋浴室数量”。通常卧室多的房子浴室也多，它们之间存在高度正相关。或者“员工工作年限”和“员工年龄”，也高度相关。
在没有正则化的情况下，多重共线性会导致以下问题：
1. **权重不稳定 (Unstable Weights)：**
    - 当特征高度相关时，模型很难确定哪个特征对预测的贡献更大。例如，如果 $X_1$ 和 $X_2$ 高度相关，那么模型可以给 $X_1$ 一个大权重，给 $X_2$ 一个小权重，或者反过来，或者给两者都分配中等权重，都能达到相似的预测效果。
    - 这导致模型在训练过程中，权重的估计值会非常不稳定，对训练数据的微小变化（例如，增加或删除几个样本）都可能导致权重发生巨大变化。
    - 这种不稳定性使得模型难以收敛，并且泛化能力差。
2. **模型可解释性差：**
    - 由于权重不稳定，无法可靠地解释每个特征对预测的独立贡献。例如，无法确定是“卧室数量”还是“浴室数量”对房价的影响更大，因为它们的信息是混淆的。
3. **梯度爆炸（在某些情况下）：**
    - 在某些优化算法中，高度相关的特征可能导致损失函数曲面变得非常“扁平”且“狭窄”，梯度在某些方向上可能非常小，而在垂直于这些方向上可能非常大，这可能导致优化路径不稳定，甚至梯度爆炸。

| 特性/方面       | L1 正则化 (Lasso Regression)                                                                       | L2 正则化 (Ridge Regression / Weight Decay)                                                               |
| :---------- | :---------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------- |
| **惩罚项**     | 权重向量的L1范数                                                                                       | 权重向量的L2范数平方                                                                                            |
| **对权重的影响**  | **稀疏性 (Sparsity)**：倾向于将不重要的特征的权重**精确地压缩为零**。                                                    | **收缩 (Shrinkage)**：倾向于将所有特征的权重**均匀地压缩到接近零**，但很少精确为零。                                                   |
| **作用机制**    | **恒定拉力 / 软阈值化：** L1惩罚项的梯度是常数（$\pm \lambda$），无论权重大小，都施加一个恒定的力将其向零拉。结合软阈值操作，当权重绝对值小于某个阈值时，直接将其置零。 | **比例拉力 / 权重衰减：** L2惩罚项的梯度与权重本身成正比（$\lambda w$）。当权重接近零时，拉力也随之减弱，因此很难将其精确推到零。                            |
| **特征选择**    | **是**：由于能将权重变为零，L1正则化可以自动进行特征选择，剔除不重要的特征。                                                       | **否**：所有特征都会保留，只是权重变小，不具备自动特征选择能力。                                                                     |
| **模型可解释性**  | **高**：模型更简洁，只依赖于少数几个非零权重的特征，更容易理解哪些特征是重要的。                                                      | **中等**：所有特征都保留在模型中，且都有非零权重，模型可能不如L1正则化模型简洁。                                                            |
| **优化挑战**    | 惩罚项在 $w=0$ 处不可导，直接梯度下降可能导致权重在零点附近**震荡**。                                                        | 惩罚项处处可导，没有额外的优化挑战。                                                                                     |
| **优化方法**    | 需要使用**次梯度方法**或**近端梯度下降（核心是软阈值操作）**来处理零点不可导问题，并实现精确归零。                                           | 可以使用标准的**梯度下降**及其变种（如SGD, Adam）。                                                                       |
| **几何解释**    | 约束区域是一个**菱形**（或多维正八面体）。损失函数的等高线与菱形的**顶点**相切的可能性更大，导致某些权重为零。                                     | 约束区域是一个**圆形**（或多维球体）。损失函数的等高线与圆形的**平滑曲线**相切，通常不会在坐标轴上。                                                 |
| **处理多重共线性** | 当存在高度相关的特征时，L1正则化可能会**随机选择其中一个**特征的权重为非零，而将其他相关特征的权重设为零，结果可能不稳定。                                | 当输入特征之间存在高度相关性时，L2正则化会倾向于将这些相关特征的权重**均匀地压缩**，使得模型更加稳定和鲁棒。                                              |
| **主要优点**    | 1. **特征选择**：自动识别并剔除不重要的特征。<br>2. **模型可解释性**：模型更简洁，更容易理解。                                        | 1. **防止过拟合**：有效降低模型复杂度，提高泛化能力。<br>2. **处理多重共线性**：当特征之间高度相关时，L2正则化能更稳定地处理。                              |
| **主要缺点**    | 1. **稳定性差**：对高度相关特征的处理可能不稳定。<br>2. **优化复杂**：零点不可导，需要特殊优化算法。                                     | 1. **不进行特征选择**：所有特征都会保留，即使它们不重要。<br>2. **模型可解释性相对较差**：所有特征都参与计算。                                       |
| **适用场景**    | 1. **高维数据**：当特征数量远大于样本数量时。<br>2. **特征选择**：当需要识别最重要的特征时。<br>3. **模型可解释性**：当模型简洁性很重要时。            | 1. **通用过拟合预防**：几乎所有机器学习模型都可使用。<br>2. **多重共线性**：当输入特征之间存在高度相关性时。<br>3. **所有特征都可能相关**：当不希望任何特征的权重完全变为零时。 |
| **别名**      | Lasso (Least Absolute Shrinkage and Selection Operator)                                         | Ridge Regression, Weight Decay (权重衰减)                                                                  |
总结：L1正则化在于**稀疏性**和**特征选择**，它通过将不重要特征的权重精确地压缩为零，实现模型简化和可解释性。L2正则化在于**权重收缩**和**平滑性**，它通过将所有权重均匀地压缩到较小的值，降低模型对输入变化的敏感度，提高泛化能力，并能更好地处理多重共线性问题。


Dropout随机丢弃：**随机地“关闭”（失活）一部分神经元**，强制网络不能过度依赖任何一个特定的神经元或输入路径的防止过拟合的正则化方法。
神经网络中神经元有“共适性”，有的会高度依赖彼此，如一个神经元可能只在另一个特定神经元激活时才激活，形成一种“小团体”或“作弊”机制。这种共适应使得网络对训练数据中的特定模式过于敏感，降低了泛化能力。
训练阶段，每个隐藏层，在每次前向传播时，每个神经元都有一个**概率 $p$** 被“失活”，形成一个“残缺”的网络，做前向传播和反向传播更新。在不同的训练迭代中，或者在同一个迭代的不同 mini-batch 中，被失活的神经元组合是不同的，看成是训练了一个庞大的“瘦身版网络集”，最后推理时用无数个子网络的平均结果。体现一个**集成学习** (Ensemble Learning)想法。
推理阶段，所有的神经元都激活。为了补偿训练时神经元数量减少导致的总激活值下降，需要对神经元的输出进行缩放，乘以$(1-p)$（或在训练时，将未失活的神经元的输出乘以 $\frac{1}{1-p}$。这样在测试时就不需要进行任何缩放，直接使用训练好的权重即可。这种方法更常用，因为它简化了测试阶段的计算）。这个p通常在$0.2$ 到 $0.5$之间。
主要应用于全连接层（密集层）的隐藏神经元。**与批量归一化 (Batch Normalization, BN) 的结合：**
BN本身具有一定的正则化效果，将**Dropout层放在BN层之后**。这是因为BN层会根据 mini-batch 的统计量对激活值进行归一化，如果先Dropout再BN，BN可能会抵消Dropout引入的随机性。


BN批量归一化：**规范化每一层输入**，通过调整和缩放每一层激活函数的输入，使其均值为0、方差为1，从而稳定训练过程，加速收敛。提出的初衷是解决**内部协变量偏移 (Internal Covariate Shift, ICS)** 问题：深度神经网络中，每一层的输入都受到前一层参数变化的影响。随着训练的进行，前一层的参数不断更新，导致后一层的输入数据的分布也在不断变化。每一层都需要不断适应新的输入分布，减慢训练速度，使得模型难以收敛。还可能导致网络对学习率等超参数敏感，且容易陷入梯度饱和区。BN的直接作用是解决**梯度消失/爆炸：** 将激活值保持在激活函数的非饱和区域，从而缓解梯度消失问题；**权重对初始化敏感**。
BN 层通常插入在**全连接层或卷积层之后，激活函数之前**。对于一个 mini-batch，BN 层对每个特征（或每个神经元的输入）执行以下操作：
1.**归一化 (Normalization)**。 $\mu_B = \frac{1}{m} \sum_{i=1}^{m} x_i$ ，$\sigma_B^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2$ 。对 mini-batch 中的每个 $x_i$ 进行归一化，使其均值为0，方差为1。 $\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$，其中ε是为了防止除以0。
2.**缩放和平移 (Scale and Shift)**。$y_i = \gamma \hat{x}_i + \beta$。没有采用原始分布，是为了保留网络的表达能力（因为强制均值为0、方差为1可能会限制模型的表达力），引入了缩放因子 $\gamma$ 和平移因子 $\beta$，两个两个可学习的参数。通过反向传播学习，允许BN层执行恒等变换（如果 $\gamma= \sqrt{\sigma_B^2 + \epsilon}$ 且 $\beta = \mu_B$），或者学习到最佳的缩放和平移，以适应后续激活函数的输入范围。
推理阶段，使用在训练过程中累积的**全局均值和方差的估计值**（通常是所有 mini-batch 均值和方差的滑动平均），为了确保测试时的输出是确定性的，不受 mini-batch 大小的影响。
- **加速训练：** 显著缓解了内部协变量偏移问题，使得网络训练更快，允许使用更大的学习率。
- **提高稳定性：** 降低网络对权重初始化的敏感性。
- **缓解梯度问题：** 将激活值保持在激活函数的非饱和区域，有助于缓解梯度消失问题。
- **正则化效果：**
    - BN在每个 mini-batch 上计算统计量，引入了微小的随机性（因为每个 mini-batch 的均值和方差略有不同）。这种随机性类似于Dropout，具有一定的正则化效果，可以减少对其他正则化技术的依赖。
    - BN使得模型对权重尺度的变化不那么敏感，因为BN层会重新规范化输入。

BN和LN（layer normalization）很多时候会放在一起横向比较，但是BN多事用在前馈神经网络，LN在序列模型用的多，而且不认为有正则化能力，所以放在后面讲。


**数据增强 (Data Augmentation)**：对现有训练数据进行各种**变换**（如旋转、缩放、裁剪、翻转、添加噪声等），来**生成新的、但仍然保留原始语义的训练样本**，人为“扩展”训练数据集。经济高效的方式来增加训练数据的多样性，还能使得模型学习到对这些特定变换的**不变性 (invariance)**。通常在数据加载和预处理阶段进行。
为什么能正则化？能够接触到更广泛的数据分布，减少了模型对训练集中特定样本的依赖；增强对输入变化的适应能力；被迫学习更普遍、更抽象的特征，而不是记住训练集中的噪声或特例，使得模型更“简单”或更“平滑”，因为它需要适应更广泛的输入。
but，我们一直在追求高质量的数据集，还要人为清洗噪声。为什么反而要加噪声？
要**清洗**的噪声：数据采集过程中的错误、传感器故障、标注错误、数据传输损坏、人为录入失误等（图像中的死像素、文本中的乱码、标签错误）。噪声随机、无意义、不符合数据真实分布，会误导模型学习到错误的模式。
要**添加**的噪声：高斯噪声、椒盐噪声、随机遮挡（Cutout/Random Erasing）等，并非真正的随机错误，而是**模拟了真实世界中可能存在的、但不会改变数据语义的微小变化或不完整性**，**有结构、有目的**地添加到数据中。

集成神经网络：**模型集成（Model Ensembling）**，通过**组合多个独立训练的模型**的预测结果，来做出最终决策的策略。可以平滑掉不同模型的训练随机性带来的性能波动方差，第二可以减少偏见（特别是如果用了不同的架构来训练），第三可以探索更广阔的解空间（集成这些来自不同局部最优解的模型，其最终结果往往比任何一个单一的局部最优解要更好）。
分类任务中，集成方法可以是硬投票和软投票。硬投票：选所有模型中那个预测的类型最多的作为最终结果。软投票：加权取最值，一般比硬投票效果好。
回归任务中可以直接取平均。
更高级的继集成方法有：
**Bagging (Bootstrap Aggregating)**，从原始训练数据中有放回地随机抽取多个子集，用每个子集独立地训练一个模型。最著名的例子：**随机森林 (Random Forest)** 就是对决策树进行Bagging；
**Boosting**，串行地训练模型，每一个新模型都更关注前一个模型**做错**的样本，代表算法：AdaBoost, Gradient Boosting, XGBoost；
**Stacking (堆叠)**，训练一个“元模型”（Meta-model），任务是学习如何更好地组合第一层多个基础模型的预测结果。第一层的模型做出预测，它们的预测结果成为第二层“元模型”的训练数据。
